# Sistema de AnÃ¡lise de Viabilidade JurÃ­dica SINDEC

Sistema modular para anÃ¡lise e classificaÃ§Ã£o de viabilidade jurÃ­dica de dados do SINDEC (Sistema Nacional de InformaÃ§Ãµes de Defesa do Consumidor).

## ğŸ“‹ Funcionalidades

- **Processamento de dados SINDEC**: Carregamento, limpeza e preparaÃ§Ã£o dos dados
- **Enriquecimento via API DataJud**: Busca valores reais de processos do CNJ (opcional)
- **Estimativa de valores de causa**: Sistema backup baseado em dados histÃ³ricos
- **AnÃ¡lise de viabilidade**: ClassificaÃ§Ã£o automatizada de causas jurÃ­dicas
- **RelatÃ³rios e visualizaÃ§Ãµes**: AnÃ¡lises completas com grÃ¡ficos interativos

## ğŸš€ InstalaÃ§Ã£o

1. Clone o repositÃ³rio:
```bash
git clone <seu-repositorio>
cd sindec-analyzer
```

2. Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

## ğŸ“ Estrutura do Projeto

```
sindec-analyzer/
â”œâ”€â”€ config.py              # ConfiguraÃ§Ãµes do sistema
â”œâ”€â”€ data_processor.py      # Processamento de dados SINDEC
â”œâ”€â”€ datajud_enricher.py    # Enriquecimento via API DataJud
â”œâ”€â”€ valor_estimator.py     # Estimativa de valores de causa
â”œâ”€â”€ analyzer.py            # AnÃ¡lise e visualizaÃ§Ã£o
â”œâ”€â”€ main.py               # Script principal
â”œâ”€â”€ requirements.txt      # DependÃªncias Python
â””â”€â”€ README.md            # Este arquivo
```

## ğŸ”§ ConfiguraÃ§Ã£o

### 1. Arquivo de Dados
Coloque o arquivo CSV do SINDEC no diretÃ³rio raiz do projeto. Por padrÃ£o, o sistema procura por `PROCON_2017_21.csv`.

### 2. API DataJud (Opcional)
Para usar o enriquecimento com dados reais do CNJ:

1. Obtenha uma chave API em: https://www.cnj.jus.br/sistemas/datajud/api-publica/
2. Configure a variÃ¡vel `API_KEY` no arquivo `main.py`

```python
API_KEY = "sua_chave_api_aqui"
```

## ğŸ¯ Uso

### ExecuÃ§Ã£o Completa
```bash
python main.py
```

### Uso Modular

```python
from main import SindecProcessor

# Inicializa processador
processor = SindecProcessor(api_key="sua_api_key")  # API key opcional

# Processa arquivo
df_resultado = processor.processar_completo("seu_arquivo.csv")
```

### AnÃ¡lise de Viabilidade Individual

```python
from analyzer import ViabilityChecker

checker = ViabilityChecker()
resultado = checker.analisar_viabilidade(
    valor=5000,
    tipo_assunto="Energia ElÃ©trica",
    problema="CobranÃ§a Indevida",
    regiao="Sudeste",
    uf="SP"
)
```

### Estimativa de Valores

```python
from valor_estimator import ValorCausaEstimatorBackup

estimador = ValorCausaEstimatorBackup()
estimativa = estimador.estimar_valor_causa(
    descricao_assunto="Telefonia Celular",
    descricao_problema="CobranÃ§a indevida",
    uf="SP",
    ano=2021
)
```

## ğŸ“Š SaÃ­das

O sistema gera os seguintes arquivos:

- **`SINDEC_com_valores_causa.csv`**: Dataset completo com valores estimados
- **`SINDEC_resumo_por_assunto.csv`**: Resumo estatÃ­stico por assunto

## ğŸ” AnÃ¡lise de Viabilidade

O sistema classifica automaticamente as causas em:

- **âœ… VIÃVEL**: Recomenda aceitar a causa
- **âš ï¸ MODERADA**: Recomenda anÃ¡lise detalhada
- **âŒ NÃƒO VIÃVEL**: Recomenda rejeitar a causa

### Fatores Considerados

1. **Valor da causa**: Valores mais altos aumentam viabilidade
2. **RegiÃ£o geogrÃ¡fica**: Algumas regiÃµes tÃªm jurisprudÃªncia mais favorÃ¡vel
3. **Tipo de assunto**: Setores com boa jurisprudÃªncia (energia, telefonia, bancos)
4. **Tipo de problema**: Problemas com alta taxa de sucesso histÃ³rica

## ğŸ“ˆ Dados HistÃ³ricos

O sistema utiliza base de dados histÃ³ricos incluindo:

- AnÃ¡lises do TJSP e outros tribunais
- Estudos da ANATEL, BACEN, ANEEL, ANS
- JurisprudÃªncia do STJ
- Dados do PROCON e SENACON

## âš™ï¸ ConfiguraÃ§Ãµes AvanÃ§adas

Edite o arquivo `config.py` para personalizar:

- URLs da API DataJud
- ParÃ¢metros de processamento
- Nomes de arquivos de saÃ­da
- ConfiguraÃ§Ãµes de encoding

## ğŸ› SoluÃ§Ã£o de Problemas

### Erro de Arquivo NÃ£o Encontrado
```
âŒ Arquivo nÃ£o encontrado: PROCON_2017_21.csv
```
**SoluÃ§Ã£o**: Certifique-se de que o arquivo CSV estÃ¡ no diretÃ³rio correto.

### Erro de Encoding
```
UnicodeDecodeError: 'utf-8' codec can't decode
```
**SoluÃ§Ã£o**: O sistema estÃ¡ configurado para `windows-1252`. Verifique o encoding do seu arquivo.

### API DataJud IndisponÃ­vel
```
âŒ Erro na conexÃ£o com API DataJud
```
**SoluÃ§Ã£o**: O sistema continuarÃ¡ funcionando com estimativas baseadas em dados histÃ³ricos.

## ğŸ“ Exemplo de SaÃ­da

```
ğŸ¯ EXEMPLO: ANÃLISE DE VIABILIDADE
--------------------------------------------------
âš ï¸ Modelo nÃ£o encontrado. Usando anÃ¡lise por regras.

âœ… CAUSA VIÃVEL
RecomendaÃ§Ã£o: ACEITAR esta causa

ğŸ“Š Probabilidade VIÃVEL: 66.7%
ğŸ“Š Probabilidade NÃƒO VIÃVEL: 33.3%
ğŸ“Š Score de Viabilidade: 60/90

ğŸ¯ FATORES INFLUENCIADORES:
==================================================
 1. âš ï¸ Valor MÃ©dio (R$ 2.000-5.000) - Moderadamente favorÃ¡vel
 2. âš ï¸ RegiÃ£o Nordeste - Desafios regionais
 3. âš ï¸ Energia ElÃ©trica - Setor com boa jurisprudÃªncia
 4. âœ… CobranÃ§a Indevida - Alta taxa de sucesso histÃ³rica

ğŸ“‹ MÃ‰TODO: AnÃ¡lise por Regras de NegÃ³cio
ğŸ¯ CONFIANÃ‡A: 66.7%
```

## ğŸ¤ ContribuiÃ§Ãµes

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/nova-feature`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona nova feature'`)
4. Push para a branch (`git push origin feature/nova-feature`)
5. Abra um Pull Request

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo `LICENSE` para mais detalhes.

## ğŸ“ Suporte

Para dÃºvidas ou problemas:
1. Verifique a seÃ§Ã£o de SoluÃ§Ã£o de Problemas
2. Abra uma issue no GitHub
3. Consulte a documentaÃ§Ã£o das APIs utilizadas


##########################################################################################################################

# Sistema de ClassificaÃ§Ã£o de Viabilidade de Causas JurÃ­dicas

Este projeto implementa um sistema de machine learning para classificar a viabilidade financeira de causas jurÃ­dicas baseado em dados do SINDEC (Sistema Nacional de InformaÃ§Ãµes de Defesa do Consumidor).

## ğŸ“‹ VisÃ£o Geral

O sistema analisa descriÃ§Ãµes de assuntos e problemas de reclamaÃ§Ãµes de consumidores para determinar se uma causa Ã© **VIÃVEL** ou **NÃƒO VIÃVEL** financeiramente para escritÃ³rios de advocacia.

### ğŸ¯ Objetivo

Criar um modelo que classifique automaticamente a viabilidade de causas baseado em:
- DescriÃ§Ã£o do assunto
- DescriÃ§Ã£o do problema  
- Valor estimado da causa
- Taxa de sucesso histÃ³rica
- Dados regionais e demogrÃ¡ficos

## ğŸ—ï¸ Arquitetura do Sistema

```
â”œâ”€â”€ config.py              # ConfiguraÃ§Ãµes gerais
â”œâ”€â”€ data_preprocessing.py   # Limpeza e preprocessamento
â”œâ”€â”€ exploratory_analysis.py # AnÃ¡lise exploratÃ³ria  
â”œâ”€â”€ target_creation.py      # CriaÃ§Ã£o da variÃ¡vel target
â”œâ”€â”€ feature_engineering.py  # Engenharia de features
â”œâ”€â”€ data_balancing.py       # Balanceamento de dados
â”œâ”€â”€ utils.py               # FunÃ§Ãµes utilitÃ¡rias
â”œâ”€â”€ main.py                # Pipeline principal
â”œâ”€â”€ requirements.txt       # DependÃªncias
â””â”€â”€ README.md             # Esta documentaÃ§Ã£o
```

## ğŸš€ InstalaÃ§Ã£o

### PrÃ©-requisitos

- Python 3.8+
- Git

### ConfiguraÃ§Ã£o

1. **Clone o repositÃ³rio:**
```bash
git clone <url-do-repositorio>
cd viabilidade-causas-juridicas
```

2. **Crie um ambiente virtual:**
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows
```

3. **Instale as dependÃªncias:**
```bash
pip install -r requirements.txt
```

## ğŸ“Š Uso

### ExecuÃ§Ã£o BÃ¡sica

```bash
python main.py dados_sindec.csv
```

### ExecuÃ§Ã£o AvanÃ§ada

```bash
# Com TF-IDF (mais lento, mais features)
python main.py dados_sindec.csv --tfidf

# Com estratÃ©gia especÃ­fica de balanceamento
python main.py dados_sindec.csv --strategy moderate

# Combinando opÃ§Ãµes
python main.py dados_sindec.csv --tfidf --strategy aggressive
```

### EstratÃ©gias de Balanceamento

- **`auto`**: SeleÃ§Ã£o automÃ¡tica baseada no desbalanceamento
- **`conservative`**: Balanceamento suave (undersampling leve)
- **`moderate`**: Balanceamento mÃ©dio (SMOTE) - **Recomendado**
- **`aggressive`**: Balanceamento agressivo (SMOTE + limpeza)

## ğŸ“ Arquivos Gerados

ApÃ³s a execuÃ§Ã£o, o sistema gera:

- `dados_preprocessados.csv` - Dados apÃ³s limpeza
- `dados_com_target.csv` - Dados com variÃ¡vel target criada
- `dados_com_features.csv` - Dados com features engineered
- `dados_balanceados.csv` - Dados finais prontos para ML
- `relatorio_qualidade.txt` - RelatÃ³rio de qualidade dos dados

## ğŸ”§ MÃ³dulos

### 1. data_preprocessing.py
**Funcionalidade:** Limpeza e preprocessamento dos dados brutos
- Remove valores invÃ¡lidos da coluna 'Atendida'
- Trata valores nulos
- Valida consistÃªncia dos dados

### 2. exploratory_analysis.py  
**Funcionalidade:** AnÃ¡lise exploratÃ³ria abrangente
- EstatÃ­sticas descritivas
- AnÃ¡lise por tipo de assunto/problema
- IdentificaÃ§Ã£o de padrÃµes de viabilidade
- Insights preliminares

### 3. target_creation.py
**Funcionalidade:** CriaÃ§Ã£o da variÃ¡vel target baseada em critÃ©rios de viabilidade
- Calcula estatÃ­sticas histÃ³ricas por assunto
- Define critÃ©rios de viabilidade (valor, taxa de sucesso, etc.)
- Cria scores compostos e classificaÃ§Ã£o final

### 4. feature_engineering.py
**Funcionalidade:** CriaÃ§Ã£o de features para machine learning
- Features de texto (comprimento, palavras-chave jurÃ­dicas)
- Features categÃ³ricas (regiÃ£o, empresa, temporais)
- Features numÃ©ricas (transformaÃ§Ãµes de valor)
- TF-IDF opcional para anÃ¡lise avanÃ§ada de texto

### 5. data_balancing.py
**Funcionalidade:** Balanceamento de classes para ML
- MÃºltiplas estratÃ©gias (SMOTE, undersampling, hÃ­bridas)
- AvaliaÃ§Ã£o comparativa de estratÃ©gias
- Balanceamento adaptativo

### 6. utils.py
**Funcionalidade:** FunÃ§Ãµes utilitÃ¡rias
- Debug de DataFrames
- RelatÃ³rios de qualidade
- VisualizaÃ§Ãµes
- ValidaÃ§Ãµes

## ğŸ“ˆ Pipeline de Processamento

```mermaid
graph TD
    A[Dados Brutos CSV] --> B[Preprocessamento]
    B --> C[AnÃ¡lise ExploratÃ³ria]
    C --> D[CriaÃ§Ã£o do Target]
    D --> E[Feature Engineering]
    E --> F[Balanceamento]
    F --> G[Dados para ML]
```

### Etapas Detalhadas:

1. **Preprocessamento**: Limpeza bÃ¡sica, remoÃ§Ã£o de inconsistÃªncias
2. **AnÃ¡lise ExploratÃ³ria**: CompreensÃ£o dos padrÃµes nos dados
3. **CriaÃ§Ã£o do Target**: DefiniÃ§Ã£o de critÃ©rios de viabilidade
4. **Feature Engineering**: CriaÃ§Ã£o de features preditivas
5. **Balanceamento**: CorreÃ§Ã£o do desbalanceamento de classes
6. **Output**: Dados prontos para treinamento de modelos

## ğŸ¯ CritÃ©rios de Viabilidade

O sistema classifica uma causa como **VIÃVEL** baseado em:

### Scores Componentes (0-10 pontos):
- **Score Valor** (0-3): Baseado no valor da causa
- **Score Sucesso** (0-3): Taxa de sucesso histÃ³rica do tipo de assunto  
- **Score Potencial** (0-2): Potencial financeiro esperado
- **Score ConfianÃ§a** (0-1): Confiabilidade da estimativa
- **Score Volume** (0-1): Volume histÃ³rico de casos similares

### ClassificaÃ§Ã£o Final:
- **Score â‰¥ 7**: ALTA viabilidade
- **Score 5-6**: MÃ‰DIA viabilidade  
- **Score 3-4**: BAIXA viabilidade
- **Score < 3**: NÃƒO VIÃVEL

**Target BinÃ¡rio para ML**: Score â‰¥ 5 = VIÃVEL (1), Score < 5 = NÃƒO VIÃVEL (0)

## ğŸ” Features Criadas

### Features de Texto:
- Comprimento de assunto/problema
- Contagem de palavras-chave jurÃ­dicas
- Scores de gravidade e complexidade
- DetecÃ§Ã£o de tipos de problema (dano moral, cobranÃ§a indevida, etc.)
- IdentificaÃ§Ã£o de setores (financeiro, telecom, etc.)

### Features CategÃ³ricas:
- Encoding de UF e regiÃ£o
- CaracterÃ­sticas demogrÃ¡ficas do consumidor
- Features temporais (mÃªs, trimestre, sazonalidade)
- CaracterÃ­sticas da empresa (porte, setor)

### Features NumÃ©ricas:
- TransformaÃ§Ãµes logarÃ­tmicas de valores
- Faixas de valor categorizadas
- Scores de confiabilidade
- Ratios e comparaÃ§Ãµes

## âš™ï¸ ConfiguraÃ§Ã£o

Principais configuraÃ§Ãµes em `config.py`:

```python
RANDOM_STATE = 42          # Reprodutibilidade
MAX_FEATURES_TFIDF = 100   # MÃ¡ximo features TF-IDF
MIN_DF = 5                 # MÃ­nimo documentos para TF-IDF
MAX_DF = 0.8              # MÃ¡ximo % documentos para TF-IDF
```

## ğŸ“Š Exemplo de SaÃ­da

```
ğŸ¯ EXECUTANDO PIPELINE COMPLETO DE CLASSIFICAÃ‡ÃƒO DE VIABILIDADE
================================================================================

ğŸ“‚ CARREGANDO DADOS
===============================
âœ… Dados carregados: (50482, 32)

ğŸ”„ ETAPA 1: PREPROCESSAMENTO
âœ… dados_preprocessados.csv salvo

ğŸ”„ ETAPA 2: ANÃLISE EXPLORATÃ“RIA  
ğŸ“Š Total de registros: 50,482
ğŸ“Š Taxa de sucesso: 59.5%
ğŸ’° Valor mÃ©dio: R$ 2,656.98

ğŸ”„ ETAPA 3: CRIAÃ‡ÃƒO DO TARGET
ğŸ“Š DistribuiÃ§Ã£o do Target BinÃ¡rio:
   VIÃVEL: 42,200 (83.6%)
   NÃƒO VIÃVEL: 8,282 (16.4%)

ğŸ”„ ETAPA 4: FEATURE ENGINEERING
ğŸ“Š Features criadas: 45
ğŸ“Š Shape final: (50482, 77)

ğŸ”„ ETAPA 5: BALANCEAMENTO DE DADOS
ğŸ“Š EstratÃ©gia automÃ¡tica selecionada: MODERATE
ğŸ“Š Amostras balanceadas: 67,344

ğŸ¯ DADOS PRONTOS PARA MACHINE LEARNING!
   Shape X: (67344, 45)
   Shape y: (67344,)
```

## ğŸ¤ Uso dos Dados Processados

ApÃ³s executar o pipeline, vocÃª pode usar os dados para ML:

```python
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split

# Carrega dados balanceados
df = pd.read_csv('dados_balanceados.csv')
X = df.drop('target', axis=1)
y = df['target']

# Split treino/teste
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42, stratify=y
)

# Treina modelo
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

# Avalia
score = model.score(X_test, y_test)
print(f"AcurÃ¡cia: {score:.3f}")
```

## ğŸ“ LicenÃ§a

Este projeto estÃ¡ licenciado sob a MIT License.

## ğŸ› Problemas Conhecidos

- TF-IDF pode ser lento para datasets grandes (>10k linhas)
- Balanceamento agressivo pode gerar overfitting
- Requer ajuste fino dos critÃ©rios de viabilidade por domÃ­nio

## ğŸ”® PrÃ³ximos Passos

- ImplementaÃ§Ã£o de modelos de ML (Random Forest, XGBoost, etc.)
- Sistema de avaliaÃ§Ã£o e mÃ©tricas
- Interface web para prediÃ§Ãµes
- API REST para integraÃ§Ã£o
- Monitoramento de drift dos dados

---

**Desenvolvido para classificaÃ§Ã£o de viabilidade de causas jurÃ­dicas usando dados do SINDEC**

##########################################################################################################################

# Algoritmo de ClassificaÃ§Ã£o SINDEC - Parte 3

MÃ³dulo para balanceamento de dados e treinamento de modelos de classificaÃ§Ã£o para anÃ¡lise de viabilidade jurÃ­dica.

## InstalaÃ§Ã£o

```bash
pip install -r requirements.txt
```

## Estrutura do Projeto

```
â”œâ”€â”€ config.py              # ConfiguraÃ§Ãµes e constantes
â”œâ”€â”€ data_preparation.py     # PreparaÃ§Ã£o de dados para balanceamento
â”œâ”€â”€ balancing.py           # FunÃ§Ãµes principais de balanceamento
â”œâ”€â”€ clean_features.py      # CriaÃ§Ã£o de features limpas (sem data leakage)
â”œâ”€â”€ model_training.py      # Treinamento de modelos
â”œâ”€â”€ main.py               # Arquivo principal e orquestraÃ§Ã£o
â”œâ”€â”€ requirements.txt      # DependÃªncias
â””â”€â”€ README.md            # Este arquivo
```

## Uso BÃ¡sico

### 1. Pipeline Completo (Recomendado)

```python
from main import executar_pipeline_completo

# Executa anÃ¡lise completa com balanceamento e treinamento
resultados = executar_pipeline_completo(
    df_com_target,
    strategy='moderate',
    run_analysis=True
)

# Acessa resultados
melhor_modelo = resultados['best_model']['model']
df_balanceado = resultados['data']['df_balanced']
```

### 2. Pipeline Simplificado (Mais RÃ¡pido)

```python
from main import executar_pipeline_simples

# ExecuÃ§Ã£o mais rÃ¡pida sem anÃ¡lise detalhada
resultados = executar_pipeline_simples(
    df_com_target,
    strategy='moderate'
)

melhor_modelo = resultados['best_model']
```

### 3. Uso Modular

```python
# Apenas balanceamento
from balancing import aplicar_balanceamento_sindec
df_balanced, results = aplicar_balanceamento_sindec(df_com_target)

# Apenas treinamento de modelos limpos
from model_training import treinar_modelo_limpo
resultados, X_train, X_test, y_train, y_test, features = treinar_modelo_limpo(df_balanced)
```

### 4. Salvar e Carregar Modelo

```python
from main import salvar_modelo_final, carregar_modelo_final, fazer_predicao

# Salvar modelo treinado
salvar_modelo_final(melhor_modelo, feature_names, 'meu_modelo.pkl')

# Carregar modelo
modelo_data = carregar_modelo_final('meu_modelo.pkl')

# Fazer prediÃ§Ãµes
predicoes, probabilidades = fazer_predicao(modelo_data, dados_novos)
```

## EstratÃ©gias de Balanceamento

- `'conservative'`: Balanceamento conservador
- `'moderate'`: Balanceamento moderado (padrÃ£o)
- `'aggressive'`: Balanceamento agressivo
- `'auto'`: Seleciona automaticamente a melhor estratÃ©gia

## DependÃªncias Externas

âš ï¸ **IMPORTANTE**: Este mÃ³dulo depende da classe `DataBalancer` que deve ter sido criada nas partes 1 e 2 do algoritmo. Certifique-se de que as partes anteriores foram executadas antes de usar este mÃ³dulo.

## Features Utilizadas

O mÃ³dulo automaticamente:
- Remove features que causam data leakage
- Cria features geogrÃ¡ficas, demogrÃ¡ficas e temporais
- Aplica transformaÃ§Ãµes de valor e encoding categÃ³rico
- Seleciona apenas features numÃ©ricas para ML

## Modelos Treinados

- Random Forest Classifier
- Gradient Boosting Classifier  
- Logistic Regression

O melhor modelo Ã© selecionado automaticamente baseado na mÃ©trica AUC.

## Exemplo Completo

```python
import pandas as pd
from main import executar_pipeline_completo, salvar_modelo_final

# Carrega dados com target jÃ¡ criado
df_com_target = pd.read_csv('dados_com_target.csv')

# Executa pipeline completo
print("Executando pipeline completo...")
resultados = executar_pipeline_completo(
    df_com_target,
    strategy='moderate',
    run_analysis=True
)

# Salva melhor modelo
if resultados:
    melhor_modelo = resultados['best_model']['model']
    feature_names = resultados['data']['feature_names']
    
    salvar_modelo_final(melhor_modelo, feature_names)
    print(f"âœ… Pipeline concluÃ­do! Melhor modelo: {resultados['best_model']['name']}")
```

## Troubleshooting

### Erro: "DataBalancer nÃ£o encontrado"
- Execute as partes 1 e 2 do algoritmo primeiro
- Certifique-se de que a classe DataBalancer estÃ¡ disponÃ­vel no ambiente

### Erro: "Coluna 'Viavel' nÃ£o encontrada"
- Verifique se o target foi criado corretamente nas etapas anteriores
- O DataFrame de entrada deve conter a coluna 'Viavel' com valores 0/1

### Performance baixa do modelo
- Verifique a qualidade dos dados de entrada
- Considere ajustar a estratÃ©gia de balanceamento
- Execute anÃ¡lise completa para identificar problemas

#########################################################################################################################

# âš–ï¸ Sistema de AnÃ¡lise de Viabilidade JurÃ­dica

Sistema inteligente para anÃ¡lise de viabilidade de causas jurÃ­dicas baseado em Machine Learning.

## ğŸ“‹ Funcionalidades

- ğŸ” **AnÃ¡lise Individual**: AnÃ¡lise detalhada de uma causa especÃ­fica
- ğŸ“Š **AnÃ¡lise em Lote**: Processamento de mÃºltiplas causas via CSV
- ğŸ“ˆ **Dashboard**: Insights e estatÃ­sticas do sistema
- â„¹ï¸ **InformaÃ§Ãµes**: DocumentaÃ§Ã£o completa do sistema

## ğŸš€ InstalaÃ§Ã£o

### PrÃ©-requisitos
- Python 3.8+
- pip

### Passos de InstalaÃ§Ã£o

1. **Clone o repositÃ³rio**
```bash
git clone <seu-repositorio>
cd juridical-analyzer
```

2. **Crie um ambiente virtual**
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate  # Windows
```

3. **Instale as dependÃªncias**
```bash
pip install -r requirements.txt
```

## ğŸ¯ Como Usar

### 1. Preparar o Modelo
Antes de executar a aplicaÃ§Ã£o, vocÃª precisa ter o modelo treinado:

```python
# CÃ³digo para salvar o modelo apÃ³s treinamento:
import pickle

model_data = {
    'model': modelo,  # Seu modelo treinado
    'feature_names': feature_names,  # Lista de nomes das features
    'scaler': scaler  # Scaler se usado (opcional)
}

with open('modelo_viabilidade_final.pkl', 'wb') as f:
    pickle.dump(model_data, f)
```

### 2. Executar a AplicaÃ§Ã£o
```bash
streamlit run app.py
```

### 3. Acessar o Sistema
- Abra o navegador em: `http://localhost:8501`
- FaÃ§a upload do modelo (se necessÃ¡rio)
- Use as funcionalidades disponÃ­veis

## ğŸ“ Estrutura do Projeto

```
juridical-analyzer/
â”‚
â”œâ”€â”€ app.py                      # Arquivo principal
â”œâ”€â”€ juridical_analyzer.py       # Classe principal de anÃ¡lise
â”œâ”€â”€ config.py                   # ConfiguraÃ§Ãµes do sistema
â”œâ”€â”€ requirements.txt            # DependÃªncias
â”œâ”€â”€ README.md                   # Este arquivo
â”‚
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ styles.py              # Estilos CSS
â”‚   â””â”€â”€ model_handler.py       # ManipulaÃ§Ã£o de modelos
â”‚
â””â”€â”€ pages/
    â”œâ”€â”€ __init__.py
    â”œâ”€â”€ individual_analysis.py  # AnÃ¡lise individual
    â”œâ”€â”€ batch_analysis.py       # AnÃ¡lise em lote
    â”œâ”€â”€ dashboard.py            # Dashboard
    â””â”€â”€ about.py               # Sobre o sistema
```

## ğŸ’¡ Uso da API

### AnÃ¡lise Individual
```python
from juridical_analyzer import JuridicalAnalyzer

analyzer = JuridicalAnalyzer()

input_data = {
    'tipo_assunto': 'Bancos/Financeiro',
    'valor_causa': 5000,
    'regiao': 'Sudeste',
    'uf': 'SP',
    'sexo': 'M',
    'faixa_etaria': 3,
    'ano': 2024
}

result = analyzer.predict_viability(input_data)
print(f"ViÃ¡vel: {result['prediction']}")
print(f"Probabilidade: {result['probability_viavel']:.2%}")
```

## ğŸ“Š Formato CSV para AnÃ¡lise em Lote

O arquivo CSV deve conter as seguintes colunas:
- `tipo_assunto`: Tipo do assunto
- `valor_causa`: Valor estimado da causa
- `regiao`: RegiÃ£o (Sudeste, Sul, etc.)
- `uf`: Unidade Federativa
- `sexo`: M ou F
- `faixa_etaria`: NÃºmero de 1-7
- `ano`: Ano da causa

## âš–ï¸ ConsideraÃ§Ãµes Legais

âš ï¸ **Importante**: Este sistema Ã© uma ferramenta de apoio Ã  decisÃ£o e nÃ£o substitui a anÃ¡lise jurÃ­dica especializada.

## ğŸ”§ Suporte

Para dÃºvidas ou problemas tÃ©cnicos, abra uma issue no repositÃ³rio.

